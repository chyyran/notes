# 2021-10-18 Speedup

* In superlinear speedup, when the serial program is at a disadvantage we could possibly get superlinear speedup.
  * Some reasons could be data too large to fit into one cache
  * Sometimes in the parallel cache we already have some needed data in L3 cache
* We divide the time it takes to run the program into \(T_1\) and \(T_2\)
  * \(T_1\) is non-parallelizable, and \(T_2\) is possibly parallelizable.
  * Consider serial time = \(T = T_1 + T_2\)
  * Optimized time = \(T' = T_1' + T_2'\)
    * \(T_1' = T_1\)
    * \(T_2' \leq T_2\)
  * Speedup = \(T/T'\)
* Amdahls law
  * the maximum time of the optimized program is bounded by the fraction of sequential work
  * \(Speedup(p)\) is thus bounded by \(1/T_1\), where \(p\) is the number of processors.
  * Consider \(T = T_1 + T_2 = 1\)
    * \(T_2 = 1-T_1\), and so \(T_1\) (Amdahl) fraction is the fraction of work parallelizable
    * \(S(p) = T/T' \leq 1(T_1 + (1-T_1)/p) \leq 1/T_1\)
  * Even if the parallel part is optimized away (perfect performance), we are limited by the sequential part.
* Efficiency
  * Fraction of time when processes are doing useful work
    * \(E = S / p\)
  * Ideal efficiency is 100% = Linear Speedup
  * Lower bound is 0% = Same as serial time
  * Efficiency of calculating sum of n array elements on n processes?
    * E = \(\theta(n / \log n) / n\)
    * E = \(\theta(1 / \log n)\)
  * The more and more processors we have we go so close to zero that we begin to not be able to determine speedup on the axis]
    * Use a log scale to map runtime
  * How can we tweak an experiment to show scaling results?
    * Strong scaling: adding more processors
      * Want to see how your algorithm scales when you add more processors
    * Weak scaling: increase input size at the same rate you are adding processors
      * Very popular when you are doing a scientific simulation
* Example speedup
  * linear speedup is ideal
  * we find that actual speedup has an asymptotic bound due to amdahl's law
  * effiency tends to zero as processors go to infinity
* carefully choose and report your serial baseline!
  * If we use 64bit for seerial and 32bit single precision for parallel
    * Single precision is much faster than double precision
    * We should use same precision for both parallel and serial
  * Using a bad algorithm/implementations for baseline
    * Should always optimize serial algorithm for baseline
    * If you realize optimizations could apply to serial, go back and use that as baseline
  * Don't report running times at all
    * report running times as well as speedup
* Shared memory architectures and parallel programming models
  * Shared memory architecture
    * Memory and IO are connected to a network bus
    * Processors access via network bus
* Programming model is made of languages and libraries that create abstract view of machine
  * Control
    * How parallelism is created
    * What orderings exist between operations
  * Data
    * What data is **private** vs **shared**
    * How is logically shared data accessed or communicated
      * Send/receive vs mutexes and locks
  * Synchronization
    * What operations can be used to coordinate parallelism
    * What are the atomic operations?
      * Writing into shared data
* POSIX Threads
  * pthreads
    * syscalls to create/sync threads
    * relatively uniform across UNIX-like OS
    * support for
      * creating paralellism
      * synchronizing
      * no explicit message passing because shared memory is implicit
* Synchronization
  * threads interact in a multiprogrammed system
    * to share resources
    * coordinate execution
  * interleaving theads could be unexpected
    * need way to restrict possible interleaving
    * scheudlign is invisible to the application
    * application can not know when we lose control of the CPU and another thread runs
    * synchronization is the mechanism that gives us control