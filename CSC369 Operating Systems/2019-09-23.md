# 2019-09-23 Filesystem Optimization

* We can filesystems optimize if we're device aware.
* Magnetic Drives (HDD)
  * Arms have actuators on the end of the arm 
  * Divide disk into track
  * Divide track into sectors
    * Sectors is a unit of writing
  * A cylinder is a set of tracks without moving the arm
    * all the tracks lined up vertically with each other.
  * Actuator does not touch the surface

* 3 components to find a sector
  * Seek to find the right track
  * Wait for the disk to rotate under the head
  * Time it takes to read the block off the disk
* We want to minimize cost of all these steps. We only have control over the seek time, because thats where we placed the blocks.
* If the arm moves to outer track too slowly, it may miss a sector and have to wait for the next rotation
  * We can skew the track locations so we have enough time to position the r/w head
* Each sector is 512 bytes, but the other sectors are physically larger
* Track buffer is a small memory chip, aound 8-16MB that caches the track
* Different from OS cache
  * Track buffer is aware of disk gemoetry
  * When reading a sector it may cache the whole track to speed up future reads on the same track
  
* Disks are messy physical devices
  * errors, bad blocks, missed seeks etc
  * OS should hide this complexity

* OS wants to schedule disk requests
  * FCFS (first come first serve) - do nothing
    * reasonable when load is load
    * long waiting times for long request queues
  * SSTF (shortest seek time first)
    * shortest number of tracks do we need to seek to get to the next request?
  * SCAN (elevator)
    * go in one direction and then comes down
    * service all requests going in 1 direction then other way around
    * biased towards middle
  * C-SCAN
    * Instead of going back and forth, we only go in 1 direction and then seek back
* Each layer abstracts details below it
* As the OS, we think about the disk as an array of blocks.
  * How do we choose which blocks to allocate?
  * **Closeness**: reduce seek times by placing related things close to one another.
  * **Amortization**: amortize each positioning delay by grabbing lots of useful data
* With inodes, as the FS grows, the allocations are independent
  * the block chosen are arbitrary, so its hard to achieve closeness and amortiation
* **Fast File System (FFS)**
  * Each block has a logical block number (LBN)
  * On a new FS, blocks are allocated sequentually, close to each other.
    * As FS gets older, files are deleted and make random gaps
    * then disk gets fragmented -> lots of seeks
  * Since inodes are allocated far from the blocks, we need to seek back and forth the disk.
  * It was the first FS that was device aware
    * it divided the disk into cylinder groups
    * Allocating in cylinder groups provides closeness
      * replicating the superblock for reliability
      * data blocks in the same file allocated in the same cylinder group
      * files in same directory allocated in the same cylinder group
      * inodes for files allocated in the same cylinder group
    * Each group would only fill up to 90% full to allow some reserve space
  * Small blocks (1K) caused problems
    * low bandwith utilization
    * small max file size
    * fixed with a larger block size (4K)
      * large files, only need 2 levels of indirection for \(2^32\)
      * fixed internal fragmentation by being able to split up 1 block into 4 1K fragments
  
* FAT
  * uses file table
  * linked list allocation
* NTFS
  * Master File Table Record
  * `data` attr indicates the starting block and the number of blocks in a 'run' or extent.
  * If all the records dont fit, you can just add another record.
  * Metadata is stored in key-value pairs
  * Directory entries are stored in a simple list right in the MFT record
  * Larger directories use BTrees
  * For a small file, the file can be stored right in the MFT record.